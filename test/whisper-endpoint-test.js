/**
 * Whisper Endpoint Test
 * ÏÉàÎ°úÏö¥ Azure Cognitive Services Whisper ÏóîÎìúÌè¨Ïù∏Ìä∏ ÌÖåÏä§Ìä∏
 */

import { WhisperService } from '../src/services/whisper.js';

// Whisper ÏÑ§Ï†ï (ÌôòÍ≤Ω Î≥ÄÏàòÏóêÏÑú ÏùΩÍ∏∞)
const whisperApiKey = process.env.WHISPER_API_KEY || 'YOUR_WHISPER_API_KEY_HERE';
const whisperEndpoint = process.env.WHISPER_ENDPOINT || 'https://info-mg6frpzu-eastus2.cognitiveservices.azure.com';
const whisperApiVersion = process.env.WHISPER_API_VERSION || '2024-06-01';

console.log('üé§ Whisper Endpoint Test\n');

// ÏÑ§Ï†ï ÌôïÏù∏
console.log('üìã Configuration:');
console.log(`- Endpoint: ${whisperEndpoint}`);
console.log(`- API Version: ${whisperApiVersion}`);
console.log(`- API Key: ${whisperApiKey ? whisperApiKey.substring(0, 8) + '...' : 'Not set'}\n`);

// WhisperService Ï¥àÍ∏∞Ìôî ÌÖåÏä§Ìä∏
console.log('üîß Service Initialization:');
try {
  const whisperService = new WhisperService(whisperApiKey, whisperEndpoint, whisperApiVersion);

  console.log(`‚úÖ WhisperService created successfully`);
  console.log(`- Base URL: ${whisperService.baseUrl}`);
  console.log(`- API Version: ${whisperService.apiVersion}`);

  // URL Íµ¨Ï°∞ Í≤ÄÏ¶ù
  const expectedBaseUrl = `${whisperEndpoint}/openai/deployments/whisper/audio/transcriptions`;
  if (whisperService.baseUrl === expectedBaseUrl) {
    console.log('‚úÖ Base URL is correctly formatted');
  } else {
    console.log('‚ùå Base URL mismatch');
    console.log(`  Expected: ${expectedBaseUrl}`);
    console.log(`  Actual: ${whisperService.baseUrl}`);
  }

} catch (error) {
  console.log(`‚ùå Service initialization failed: ${error.message}`);
}

// ÏãúÍ∞Ñ Ìè¨Îß∑ÌåÖ ÌÖåÏä§Ìä∏
console.log('\n‚è∞ Time Formatting Tests:');
try {
  const whisperService = new WhisperService(whisperApiKey, whisperEndpoint, whisperApiVersion);

  // SRT ÏãúÍ∞Ñ Ìè¨Îß∑ ÌÖåÏä§Ìä∏
  const srtTime = whisperService.formatSRTTime(65.5);
  const expectedSrtTime = '00:01:05,500';

  if (srtTime === expectedSrtTime) {
    console.log(`‚úÖ SRT time formatting: ${srtTime}`);
  } else {
    console.log(`‚ùå SRT time formatting failed: expected ${expectedSrtTime}, got ${srtTime}`);
  }

  // VTT ÏãúÍ∞Ñ Ìè¨Îß∑ ÌÖåÏä§Ìä∏
  const vttTime = whisperService.formatVTTTime(65.5);
  const expectedVttTime = '00:01:05.500';

  if (vttTime === expectedVttTime) {
    console.log(`‚úÖ VTT time formatting: ${vttTime}`);
  } else {
    console.log(`‚ùå VTT time formatting failed: expected ${expectedVttTime}, got ${vttTime}`);
  }

} catch (error) {
  console.log(`‚ùå Time formatting test failed: ${error.message}`);
}

// API ÏóîÎìúÌè¨Ïù∏Ìä∏ Ïó∞Í≤∞ ÌÖåÏä§Ìä∏ (Ïã§Ï†ú ÏöîÏ≤≠ ÏóÜÏù¥)
console.log('\nüåê API Endpoint Test:');
if (whisperApiKey && whisperEndpoint) {

  // Mock FormData for testing
  global.FormData = class MockFormData {
    constructor() {
      this.data = new Map();
    }
    append(key, value, filename) {
      this.data.set(key, { value, filename });
    }
    get(key) {
      return this.data.get(key);
    }
  };

  // Mock Blob for testing
  global.Blob = class MockBlob {
    constructor(data, options = {}) {
      this.data = data;
      this.type = options.type || 'application/octet-stream';
    }
  };

  try {
    const whisperService = new WhisperService(whisperApiKey, whisperEndpoint, whisperApiVersion);

    // FormData Íµ¨ÏÑ± ÌÖåÏä§Ìä∏
    const mockBlob = new Blob(['test audio data'], { type: 'audio/mp3' });
    const formData = new FormData();
    formData.append('file', mockBlob, 'audio.mp3');
    formData.append('model', 'whisper');
    formData.append('response_format', 'verbose_json');

    console.log('‚úÖ FormData construction successful');
    console.log(`- File type: ${formData.get('file').value.type}`);
    console.log(`- Model: ${formData.get('model').value}`);
    console.log(`- Response format: ${formData.get('response_format').value}`);

    // URL Íµ¨ÏÑ± ÌÖåÏä§Ìä∏
    const fullUrl = `${whisperService.baseUrl}?api-version=${whisperService.apiVersion}`;
    console.log(`‚úÖ Full API URL: ${fullUrl}`);

    // Ìó§Îçî Íµ¨ÏÑ± ÌÖåÏä§Ìä∏
    const headers = {
      'api-key': whisperService.apiKey
    };
    console.log(`‚úÖ Headers configured with api-key`);

  } catch (error) {
    console.log(`‚ùå API setup test failed: ${error.message}`);
  }

} else {
  console.log('‚ö†Ô∏è  Skipping API test - missing API key or endpoint');
}

// Ïñ∏Ïñ¥ Îß§Ìïë ÌÖåÏä§Ìä∏ (TranscribeConsumerÏóêÏÑú ÏÇ¨Ïö©)
console.log('\nüåç Language Mapping Test:');
const languageMap = {
  'ko-KR': 'ko',
  'en-US': 'en',
  'ja-JP': 'ja',
  'zh-CN': 'zh'
};

console.log('‚úÖ Language mapping test:');
Object.entries(languageMap).forEach(([input, expected]) => {
  const result = input.split('-')[0];
  if (result === expected) {
    console.log(`  ${input} ‚Üí ${result} ‚úÖ`);
  } else {
    console.log(`  ${input} ‚Üí ${result} ‚ùå (expected ${expected})`);
  }
});

console.log('\nüìä Test Summary:');
console.log('- Configuration loaded from .env');
console.log('- Service initialization verified');
console.log('- Time formatting functions working');
console.log('- API endpoint structure validated');
console.log('- Ready for real audio transcription');

console.log('\nüöÄ Next Steps:');
console.log('1. Set Cloudflare secrets with new Whisper configuration:');
console.log('   wrangler secret put WHISPER_API_KEY');
console.log('   wrangler secret put WHISPER_ENDPOINT');
console.log('   wrangler secret put WHISPER_API_VERSION');
console.log('2. Test with actual audio file using /v1/transcribe endpoint');
console.log('3. Verify SRT/VTT output format');